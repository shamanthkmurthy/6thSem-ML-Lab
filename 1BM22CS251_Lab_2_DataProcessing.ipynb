{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwHaUGDvAemb",
        "outputId": "ed6ceedd-5e43-429a-ac1f-f03ab6a04195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20 entries, 0 to 19\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Age        19 non-null     float64\n",
            " 1   Salary     19 non-null     float64\n",
            " 2   Purchased  20 non-null     int64  \n",
            " 3   Gender     20 non-null     object \n",
            " 4   City       20 non-null     object \n",
            "dtypes: float64(2), int64(1), object(2)\n",
            "memory usage: 932.0+ bytes\n",
            "None\n",
            "             Age         Salary  Purchased\n",
            "count  19.000000      19.000000  20.000000\n",
            "mean   46.052632   76251.789474   0.550000\n",
            "std    16.510851   23696.042667   0.510418\n",
            "min    19.000000   37746.000000   0.000000\n",
            "25%    31.500000   58586.500000   0.000000\n",
            "50%    54.000000   79537.000000   1.000000\n",
            "75%    58.000000   96932.500000   1.000000\n",
            "max    69.000000  110757.000000   1.000000\n",
            "Age       1\n",
            "Salary    1\n",
            "dtype: int64\n",
            "0\n",
            "0\n",
            "    Age    Salary  Purchased  Gender_Encoded  City_Los Angeles  City_New York  \\\n",
            "0  57.0  100880.0          1             1.0               1.0            0.0   \n",
            "1  51.0  109310.0          0             0.0               0.0            1.0   \n",
            "2  41.0   70841.0          1             0.0               0.0            0.0   \n",
            "3  69.0   37746.0          1             0.0               0.0            1.0   \n",
            "4  63.0   93046.0          1             1.0               0.0            0.0   \n",
            "\n",
            "   City_San Francisco  \n",
            "0                 0.0  \n",
            "1                 0.0  \n",
            "2                 1.0  \n",
            "3                 0.0  \n",
            "4                 1.0  \n",
            "        Age    Salary  Purchased  Gender_Encoded  City_Los Angeles  \\\n",
            "0  0.669457  0.864719          1             1.0               1.0   \n",
            "1  0.288723  0.980181          0             0.0               0.0   \n",
            "2 -0.345833  0.453288          1             0.0               0.0   \n",
            "3  1.430924  0.000000          1             0.0               0.0   \n",
            "4  1.050191  0.757420          1             1.0               0.0   \n",
            "\n",
            "   City_New York  City_San Francisco  \n",
            "0            0.0                 0.0  \n",
            "1            1.0                 0.0  \n",
            "2            0.0                 1.0  \n",
            "3            1.0                 0.0  \n",
            "4            0.0                 1.0  \n",
            "        Age    Salary  Purchased  Gender_Encoded  City_Los Angeles  \\\n",
            "0  0.669457  0.864719          1             1.0               1.0   \n",
            "1  0.288723  0.980181          0             0.0               0.0   \n",
            "2 -0.345833  0.453288          1             0.0               0.0   \n",
            "3  1.430924  0.000000          1             0.0               0.0   \n",
            "4  1.050191  0.757420          1             1.0               0.0   \n",
            "\n",
            "   City_New York  City_San Francisco  Salary_zscore  \n",
            "0            0.0                 0.0       1.095559  \n",
            "1            1.0                 0.0       1.470558  \n",
            "2            0.0                 1.0      -0.240693  \n",
            "3            1.0                 0.0      -1.712888  \n",
            "4            0.0                 1.0       0.747072  \n",
            "        Age    Salary  Purchased  Gender_Encoded  City_Los Angeles  \\\n",
            "0  0.669457  0.864719          1             1.0               1.0   \n",
            "1  0.288723  0.980181          0             0.0               0.0   \n",
            "2 -0.345833  0.453288          1             0.0               0.0   \n",
            "3  1.430924  0.000000          1             0.0               0.0   \n",
            "4  1.050191  0.757420          1             1.0               0.0   \n",
            "\n",
            "   City_New York  City_San Francisco  Salary_zscore  \n",
            "0            0.0                 0.0       1.095559  \n",
            "1            1.0                 0.0       1.470558  \n",
            "2            0.0                 1.0      -0.240693  \n",
            "3            1.0                 0.0      -1.712888  \n",
            "4            0.0                 1.0       0.747072  \n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Lab-1-ML-DataPreprocessing.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1H7zMwzkuIZJvJEZFGEUB7RlUVVOPzC5M\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from scipy import stats\n",
        "\n",
        "def createdata():\n",
        "  data = {\n",
        "      'Age': np.random.randint(18, 70, size=20),\n",
        "      'Salary': np.random.randint(30000, 120000, size=20),\n",
        "      'Purchased': np.random.choice([0, 1], size=20),\n",
        "      'Gender': np.random.choice(['Male', 'Female'], size=20),\n",
        "      'City': np.random.choice(['New York', 'San Francisco', 'Los Angeles'], size=20)\n",
        "  }\n",
        "\n",
        "  df = pd.DataFrame(data)\n",
        "  return df\n",
        "\n",
        "df = createdata()\n",
        "df.head(10)\n",
        "\n",
        "df.shape\n",
        "\n",
        "# Introduce some missing values for demonstration\n",
        "df.loc[5, 'Age'] = np.nan\n",
        "df.loc[10, 'Salary'] = np.nan\n",
        "df.head(10)\n",
        "\n",
        "# Basic information about the dataset\n",
        "print(df.info())\n",
        "\n",
        "# Summary statistics\n",
        "print(df.describe())\n",
        "\n",
        "#Code to Find Missing Values\n",
        "# Check for missing values in each column\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Display columns with missing values\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "#Set the values to some value (zero, the mean, the median, etc.).\n",
        "# Step 1: Create an instance of SimpleImputer with the median strategy for Age and mean stratergy for Salary\n",
        "imputer1 = SimpleImputer(strategy=\"median\")\n",
        "imputer2 = SimpleImputer(strategy=\"mean\")\n",
        "\n",
        "df_copy=df\n",
        "\n",
        "# Step 2: Fit the imputer on the \"Age\" and \"Salary\"column\n",
        "# Note: SimpleImputer expects a 2D array, so we reshape the column\n",
        "imputer1.fit(df_copy[[\"Age\"]])\n",
        "imputer2.fit(df_copy[[\"Salary\"]])\n",
        "\n",
        "# Step 3: Transform (fill) the missing values in the \"Age\" and \"Salary\"c column\n",
        "df_copy[\"Age\"] = imputer1.transform(df[[\"Age\"]])\n",
        "df_copy[\"Salary\"] = imputer2.transform(df[[\"Salary\"]])\n",
        "\n",
        "# Verify that there are no missing values left\n",
        "print(df_copy[\"Age\"].isnull().sum())\n",
        "print(df_copy[\"Salary\"].isnull().sum())\n",
        "\n",
        "#Handling Categorical Attributes\n",
        "#Using Ordinal Encoding for gender COlumn and One-Hot Encoding for City Column\n",
        "\n",
        "# Initialize OrdinalEncoder\n",
        "ordinal_encoder = OrdinalEncoder(categories=[[\"Male\", \"Female\"]])\n",
        "# Fit and transform the data\n",
        "df_copy[\"Gender_Encoded\"] = ordinal_encoder.fit_transform(df_copy[[\"Gender\"]])\n",
        "\n",
        "# Initialize OneHotEncoder\n",
        "onehot_encoder = OneHotEncoder()\n",
        "\n",
        "# Fit and transform the \"City\" column\n",
        "encoded_data = onehot_encoder.fit_transform(df[[\"City\"]])\n",
        "\n",
        "# Convert the sparse matrix to a dense array\n",
        "encoded_array = encoded_data.toarray()\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "encoded_df = pd.DataFrame(encoded_array, columns=onehot_encoder.get_feature_names_out([\"City\"]))\n",
        "df_encoded = pd.concat([df_copy, encoded_df], axis=1)\n",
        "\n",
        "df_encoded.drop(\"Gender\", axis=1, inplace=True)\n",
        "df_encoded.drop(\"City\", axis=1, inplace=True)\n",
        "\n",
        "print(df_encoded. head())\n",
        "\n",
        "#Data Transformation\n",
        "# Min-Max Scaler/Normalization (range 0-1)\n",
        "#Pros: Keeps all data between 0 and 1; ideal for distance-based models.\n",
        "#Cons: Can distort data distribution, especially with extreme outliers.\n",
        "normalizer = MinMaxScaler()\n",
        "df_encoded[['Salary']] = normalizer.fit_transform(df_encoded[['Salary']])\n",
        "df_encoded.head()\n",
        "\n",
        "# Standardization (mean=0, variance=1)\n",
        "#Pros: Works well for normally distributed data; suitable for many models.\n",
        "#Cons: Sensitive to outliers.\n",
        "scaler = StandardScaler()\n",
        "df_encoded[['Age']] = scaler.fit_transform(df_encoded[['Age']])\n",
        "df_encoded.head()\n",
        "\n",
        "#Removing Outliers\n",
        "# Outlier Detection and Treatment using IQR\n",
        "#Pros: Simple and effective for mild outliers.\n",
        "#Cons: May overly reduce variation if there are many extreme outliers.\n",
        "df_encoded_copy1=df_encoded\n",
        "df_encoded_copy2=df_encoded\n",
        "df_encoded_copy3=df_encoded\n",
        "\n",
        "Q1 = df_encoded_copy1['Salary'].quantile(0.25)\n",
        "Q3 = df_encoded_copy1['Salary'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "df_encoded_copy1['Salary'] = np.where(df_encoded_copy1['Salary'] > upper_bound, upper_bound,\n",
        "                        np.where(df_encoded_copy1['Salary'] < lower_bound, lower_bound, df_encoded_copy1['Salary']))\n",
        "\n",
        "print(df_encoded_copy1.head())\n",
        "\n",
        "#Removing Outliers\n",
        "# Z-score method\n",
        "#Pros: Good for normally distributed data.\n",
        "#Cons: Not suitable for non-normal data; may miss outliers in skewed distributions.\n",
        "\n",
        "df_encoded_copy2['Salary_zscore'] = stats.zscore(df_encoded_copy2['Salary'])\n",
        "df_encoded_copy2['Salary'] = np.where(df_encoded_copy2['Salary_zscore'].abs() > 3, np.nan, df_encoded_copy2['Salary'])  # Replace outliers with NaN\n",
        "print(df_encoded_copy2.head())\n",
        "\n",
        "#Removing Outliers\n",
        "# Median replacement for outliers\n",
        "#Pros: Keeps distribution shape intact, useful when capping isnâ€™t feasible.\n",
        "#Cons: May distort data if outliers represent real phenomena.\n",
        "df_encoded_copy3['Salary_zscore'] = stats.zscore(df_encoded_copy3['Salary'])\n",
        "median_salary = df_encoded_copy3['Salary'].median()\n",
        "df_encoded_copy3['Salary'] = np.where(df_encoded_copy3['Salary_zscore'].abs() > 3, median_salary, df_encoded_copy3['Salary'])\n",
        "print(df_encoded_copy3.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from scipy import stats\n",
        "\n",
        "def preprocess_data(file_path):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: '{file_path}' not found.\")\n",
        "        return None\n",
        "\n",
        "    # 1. Data Cleaning\n",
        "    # 1.1 Handling Missing Values (using SimpleImputer)\n",
        "    numerical_cols = df.select_dtypes(include=np.number).columns\n",
        "    categorical_cols = df.select_dtypes(exclude=np.number).columns\n",
        "    print(df.isnull().sum())\n",
        "    imputer_num = SimpleImputer(strategy='median')  # Use median for numerical\n",
        "    df[numerical_cols] = imputer_num.fit_transform(df[numerical_cols])\n",
        "\n",
        "    imputer_cat = SimpleImputer(strategy='most_frequent') # Use most frequent for categorical\n",
        "    df[categorical_cols] = imputer_cat.fit_transform(df[categorical_cols])\n",
        "\n",
        "\n",
        "    # 1.2 Handling Categorical Data (using OneHotEncoding)\n",
        "    for col in categorical_cols:\n",
        "        if df[col].nunique() <= 10 : # Apply one-hot only to columns with less than or equal to 10 unique values\n",
        "          onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "          encoded_data = onehot_encoder.fit_transform(df[[col]])\n",
        "          encoded_df = pd.DataFrame(encoded_data, columns=onehot_encoder.get_feature_names_out([col]))\n",
        "          df = pd.concat([df, encoded_df], axis=1).drop(columns=col)\n",
        "        else :\n",
        "          ordinal_encoder = OrdinalEncoder()\n",
        "          df[col] = ordinal_encoder.fit_transform(df[[col]])\n",
        "\n",
        "\n",
        "    # 1.3 Handling Outliers (using Z-score method)\n",
        "    for col in numerical_cols:\n",
        "        df[col + '_zscore'] = np.abs(stats.zscore(df[col]))\n",
        "        df[col] = np.where(df[col + '_zscore'] > 3, df[col].median(), df[col])\n",
        "        df = df.drop(col + '_zscore', axis=1)\n",
        "\n",
        "\n",
        "    # 2. Data Transformations\n",
        "    # 2.1 Min-Max Scaling\n",
        "    min_max_scaler = MinMaxScaler()\n",
        "    df[numerical_cols] = min_max_scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "\n",
        "    # 2.2 Standard Scaling\n",
        "    standard_scaler = StandardScaler()\n",
        "    df[numerical_cols] = standard_scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Preprocess the Diabetes dataset\n",
        "diabetes_df = preprocess_data('/content/Dataset of Diabetes .csv')\n",
        "\n",
        "if diabetes_df is not None:\n",
        "    print(\"Preprocessed Diabetes Data:\")\n",
        "    print(diabetes_df.head())\n",
        "\n",
        "\n",
        "# Preprocess the Adult Income dataset\n",
        "adult_df = preprocess_data('/content/adult.csv')\n",
        "\n",
        "if adult_df is not None:\n",
        "    print(\"\\nPreprocessed Adult Income Data:\")\n",
        "    print(adult_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKMmIbIkAqRY",
        "outputId": "652f395b-7b11-4afe-d507-01ece18eebea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID           0\n",
            "No_Pation    0\n",
            "Gender       0\n",
            "AGE          0\n",
            "Urea         0\n",
            "Cr           0\n",
            "HbA1c        0\n",
            "Chol         0\n",
            "TG           0\n",
            "HDL          0\n",
            "LDL          0\n",
            "VLDL         0\n",
            "BMI          0\n",
            "CLASS        0\n",
            "dtype: int64\n",
            "Preprocessed Diabetes Data:\n",
            "         ID  No_Pation       AGE      Urea        Cr     HbA1c      Chol  \\\n",
            "0  0.672140  -0.157106 -0.424738 -0.067182 -0.677551 -1.341068 -0.537604   \n",
            "1  1.641852  -0.124010  0.156936 -0.175155 -0.050153 -1.341068 -0.978321   \n",
            "2  0.330868  -0.095991 -0.424738 -0.067182 -0.677551 -1.341068 -0.537604   \n",
            "3  1.412950  -0.015153 -0.424738 -0.067182 -0.677551 -1.341068 -0.537604   \n",
            "4  0.680463  -0.124006 -2.402429  1.228490 -0.677551 -1.341068  0.079400   \n",
            "\n",
            "         TG       HDL       LDL      VLDL       BMI  Gender_F  Gender_M  \\\n",
            "0 -1.185936  3.266253 -1.158715 -0.497302 -1.136091       1.0       0.0   \n",
            "1 -0.744645 -0.119680 -0.465934 -0.435617 -1.341671       0.0       1.0   \n",
            "2 -1.185936  3.266253 -1.158715 -0.497302 -1.136091       1.0       0.0   \n",
            "3 -1.185936  3.266253 -1.158715 -0.497302 -1.136091       1.0       0.0   \n",
            "4 -1.097678 -0.901049 -0.564903 -0.558987 -1.752832       0.0       1.0   \n",
            "\n",
            "   Gender_f  CLASS_N  CLASS_N   CLASS_P  CLASS_Y  CLASS_Y   \n",
            "0       0.0      1.0       0.0      0.0      0.0       0.0  \n",
            "1       0.0      1.0       0.0      0.0      0.0       0.0  \n",
            "2       0.0      1.0       0.0      0.0      0.0       0.0  \n",
            "3       0.0      1.0       0.0      0.0      0.0       0.0  \n",
            "4       0.0      1.0       0.0      0.0      0.0       0.0  \n",
            "age                0\n",
            "workclass          0\n",
            "fnlwgt             0\n",
            "education          0\n",
            "educational-num    0\n",
            "marital-status     0\n",
            "occupation         0\n",
            "relationship       0\n",
            "race               0\n",
            "gender             0\n",
            "capital-gain       0\n",
            "capital-loss       0\n",
            "hours-per-week     0\n",
            "native-country     0\n",
            "income             0\n",
            "dtype: int64\n",
            "\n",
            "Preprocessed Adult Income Data:\n",
            "        age    fnlwgt  education  educational-num  occupation  capital-gain  \\\n",
            "0 -1.003723  0.444012        1.0        -1.265060         7.0     -0.236000   \n",
            "1 -0.034522 -1.009761       11.0        -0.457705         5.0     -0.236000   \n",
            "2 -0.780061  1.612959        7.0         0.753327        11.0     -0.236000   \n",
            "3  0.412802 -0.261490       15.0        -0.054028         7.0      3.191145   \n",
            "4 -1.525600 -0.864551       15.0        -0.054028         0.0     -0.236000   \n",
            "\n",
            "   capital-loss  hours-per-week  native-country  workclass_?  ...  \\\n",
            "0      -0.03383       -0.000355            39.0          0.0  ...   \n",
            "1      -0.03383        0.897615            39.0          0.0  ...   \n",
            "2      -0.03383       -0.000355            39.0          0.0  ...   \n",
            "3      -0.03383       -0.000355            39.0          0.0  ...   \n",
            "4      -0.03383       -0.898325            39.0          1.0  ...   \n",
            "\n",
            "   relationship_Wife  race_Amer-Indian-Eskimo  race_Asian-Pac-Islander  \\\n",
            "0                0.0                      0.0                      0.0   \n",
            "1                0.0                      0.0                      0.0   \n",
            "2                0.0                      0.0                      0.0   \n",
            "3                0.0                      0.0                      0.0   \n",
            "4                0.0                      0.0                      0.0   \n",
            "\n",
            "   race_Black  race_Other  race_White  gender_Female  gender_Male  \\\n",
            "0         1.0         0.0         0.0            0.0          1.0   \n",
            "1         0.0         0.0         1.0            0.0          1.0   \n",
            "2         0.0         0.0         1.0            0.0          1.0   \n",
            "3         1.0         0.0         0.0            0.0          1.0   \n",
            "4         0.0         0.0         1.0            1.0          0.0   \n",
            "\n",
            "   income_<=50K  income_>50K  \n",
            "0           1.0          0.0  \n",
            "1           1.0          0.0  \n",
            "2           0.0          1.0  \n",
            "3           0.0          1.0  \n",
            "4           1.0          0.0  \n",
            "\n",
            "[5 rows x 40 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Function to handle missing values, categorical data, and outliers\n",
        "def data_cleaning(df):\n",
        "    # Handling missing values\n",
        "    # Impute missing values with the median for numerical columns\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    df[num_cols] = imputer.fit_transform(df[num_cols])\n",
        "\n",
        "    # Impute missing values with the most frequent value for categorical columns\n",
        "    cat_cols = df.select_dtypes(include=[object]).columns\n",
        "    imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "    df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "    # Handling outliers using Z-Score method\n",
        "    from scipy import stats\n",
        "    z_scores = np.abs(stats.zscore(df[num_cols]))\n",
        "    df = df[(z_scores < 3).all(axis=1)]  # Removing rows with Z-score greater than 3\n",
        "\n",
        "    # Handling categorical data using one-hot encoding\n",
        "    df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Function to apply Min-Max Scaler and Standard Scaler\n",
        "def data_transformations(df):\n",
        "    # Min-Max Scaling\n",
        "    min_max_scaler = MinMaxScaler()\n",
        "    df_scaled_minmax = df.copy()\n",
        "    df_scaled_minmax[df.columns] = min_max_scaler.fit_transform(df)\n",
        "\n",
        "    # Standard Scaling\n",
        "    standard_scaler = StandardScaler()\n",
        "    df_scaled_standard = df.copy()\n",
        "    df_scaled_standard[df.columns] = standard_scaler.fit_transform(df)\n",
        "\n",
        "    return df_scaled_minmax, df_scaled_standard\n",
        "\n",
        "# Load the Diabetes dataset\n",
        "def load_diabetes_data():\n",
        "    # Assuming the dataset is stored as 'diabetes.csv'\n",
        "    df = pd.read_csv('/content/Dataset of Diabetes .csv')\n",
        "    df_cleaned = data_cleaning(df)\n",
        "    df_minmax, df_standard = data_transformations(df_cleaned)\n",
        "    return df_cleaned, df_minmax, df_standard\n",
        "\n",
        "# Load the Adult Income dataset\n",
        "def load_adult_income_data():\n",
        "    # Assuming the dataset is stored as 'adult.csv'\n",
        "    df = pd.read_csv('/content/adult.csv')\n",
        "    df_cleaned = data_cleaning(df)\n",
        "    df_minmax, df_standard = data_transformations(df_cleaned)\n",
        "    return df_cleaned, df_minmax, df_standard\n",
        "\n",
        "# Example: Preprocessing Diabetes Dataset\n",
        "df_diabetes_cleaned, df_diabetes_minmax, df_diabetes_standard = load_diabetes_data()\n",
        "print(f\"Diabetes Data after Cleaning and Transformation (Min-Max Scaled):\\n{df_diabetes_minmax.head()}\")\n",
        "\n",
        "# Example: Preprocessing Adult Income Dataset\n",
        "df_adult_cleaned, df_adult_minmax, df_adult_standard = load_adult_income_data()\n",
        "print(f\"Adult Income Data after Cleaning and Transformation (Min-Max Scaled):\\n{df_adult_minmax.head()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ftw5Dc8HB5-8",
        "outputId": "b04918cc-502f-4891-d5e4-266ba7db4fb3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diabetes Data after Cleaning and Transformation (Min-Max Scaled):\n",
            "         ID  No_Pation       AGE      Urea        Cr     HbA1c      Chol  \\\n",
            "0  0.626566   0.002032  0.431373  0.328125  0.203046  0.283688  0.405405   \n",
            "2  0.523810   0.005447  0.431373  0.328125  0.203046  0.283688  0.405405   \n",
            "3  0.849624   0.009963  0.431373  0.328125  0.203046  0.283688  0.405405   \n",
            "4  0.629073   0.003881  0.098039  0.515625  0.203046  0.283688  0.500000   \n",
            "5  0.791980   0.003881  0.333333  0.140625  0.091371  0.219858  0.229730   \n",
            "\n",
            "         TG       HDL       LDL      VLDL       BMI  Gender_M  Gender_f  \\\n",
            "0  0.100000  0.758621  0.207547  0.031746  0.238095       0.0       0.0   \n",
            "2  0.100000  0.758621  0.207547  0.031746  0.238095       0.0       0.0   \n",
            "3  0.100000  0.758621  0.207547  0.031746  0.238095       0.0       0.0   \n",
            "4  0.116667  0.206897  0.320755  0.023810  0.095238       1.0       0.0   \n",
            "5  0.116667  0.275862  0.226415  0.023810  0.095238       0.0       0.0   \n",
            "\n",
            "   CLASS_N   CLASS_P  CLASS_Y  CLASS_Y   \n",
            "0       0.0      0.0      0.0       0.0  \n",
            "2       0.0      0.0      0.0       0.0  \n",
            "3       0.0      0.0      0.0       0.0  \n",
            "4       0.0      0.0      0.0       0.0  \n",
            "5       0.0      0.0      0.0       0.0  \n",
            "Adult Income Data after Cleaning and Transformation (Min-Max Scaled):\n",
            "        age    fnlwgt  educational-num  capital-gain  capital-loss  \\\n",
            "0  0.129032  0.434112         0.307692       0.00000           0.0   \n",
            "1  0.338710  0.156893         0.461538       0.00000           0.0   \n",
            "2  0.177419  0.657018         0.692308       0.00000           0.0   \n",
            "3  0.435484  0.299580         0.538462       0.34882           0.0   \n",
            "4  0.016129  0.184583         0.538462       0.00000           0.0   \n",
            "\n",
            "   hours-per-week  workclass_Federal-gov  workclass_Local-gov  \\\n",
            "0        0.493151                    0.0                  0.0   \n",
            "1        0.630137                    0.0                  0.0   \n",
            "2        0.493151                    0.0                  1.0   \n",
            "3        0.493151                    0.0                  0.0   \n",
            "4        0.356164                    0.0                  0.0   \n",
            "\n",
            "   workclass_Never-worked  workclass_Private  ...  native-country_Puerto-Rico  \\\n",
            "0                     0.0                1.0  ...                         0.0   \n",
            "1                     0.0                1.0  ...                         0.0   \n",
            "2                     0.0                0.0  ...                         0.0   \n",
            "3                     0.0                1.0  ...                         0.0   \n",
            "4                     0.0                0.0  ...                         0.0   \n",
            "\n",
            "   native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
            "0                      0.0                   0.0                    0.0   \n",
            "1                      0.0                   0.0                    0.0   \n",
            "2                      0.0                   0.0                    0.0   \n",
            "3                      0.0                   0.0                    0.0   \n",
            "4                      0.0                   0.0                    0.0   \n",
            "\n",
            "   native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
            "0                      0.0                             0.0   \n",
            "1                      0.0                             0.0   \n",
            "2                      0.0                             0.0   \n",
            "3                      0.0                             0.0   \n",
            "4                      0.0                             0.0   \n",
            "\n",
            "   native-country_United-States  native-country_Vietnam  \\\n",
            "0                           1.0                     0.0   \n",
            "1                           1.0                     0.0   \n",
            "2                           1.0                     0.0   \n",
            "3                           1.0                     0.0   \n",
            "4                           1.0                     0.0   \n",
            "\n",
            "   native-country_Yugoslavia  income_>50K  \n",
            "0                        0.0          0.0  \n",
            "1                        0.0          0.0  \n",
            "2                        0.0          1.0  \n",
            "3                        0.0          1.0  \n",
            "4                        0.0          0.0  \n",
            "\n",
            "[5 rows x 98 columns]\n"
          ]
        }
      ]
    }
  ]
}
