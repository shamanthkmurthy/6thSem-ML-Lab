{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH00Fmei-pEu",
        "outputId": "765eaa22-2d77-493a-ede7-c240ac5c91dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 100.00%\n",
            "Decision Tree Structure:\n",
            "Feature 0 <= 0.0\n",
            "  Leaf: 1\n",
            "  Leaf: 0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/weatherHistory.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Drop rows where 'Precip Type' is missing\n",
        "df = df.dropna(subset=['Precip Type'])\n",
        "\n",
        "# Encode the target variable ('Precip Type') into numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Precip Type'] = label_encoder.fit_transform(df['Precip Type'])\n",
        "\n",
        "# Select relevant features\n",
        "features = ['Temperature (C)', 'Humidity', 'Wind Speed (km/h)',\n",
        "            'Wind Bearing (degrees)', 'Visibility (km)', 'Pressure (millibars)']\n",
        "X = df[features].to_numpy()\n",
        "y = df['Precip Type'].to_numpy()\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to calculate entropy\n",
        "def entropy(y):\n",
        "    counts = np.bincount(y)\n",
        "    probabilities = counts / len(y)\n",
        "    return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
        "\n",
        "# Function to calculate information gain\n",
        "def information_gain(X_column, y, threshold):\n",
        "    left_mask = X_column <= threshold\n",
        "    right_mask = X_column > threshold\n",
        "\n",
        "    parent_entropy = entropy(y)\n",
        "    left_entropy = entropy(y[left_mask])\n",
        "    right_entropy = entropy(y[right_mask])\n",
        "\n",
        "    n = len(y)\n",
        "    left_weight = len(y[left_mask]) / n\n",
        "    right_weight = len(y[right_mask]) / n\n",
        "    child_entropy = (left_weight * left_entropy) + (right_weight * right_entropy)\n",
        "\n",
        "    return parent_entropy - child_entropy\n",
        "\n",
        "# Function to find the best feature and threshold for splitting\n",
        "def best_split(X, y):\n",
        "    best_gain = 0\n",
        "    best_feature = None\n",
        "    best_threshold = None\n",
        "\n",
        "    for feature in range(X.shape[1]):\n",
        "        X_column = X[:, feature]\n",
        "        thresholds = np.unique(X_column)\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            gain = information_gain(X_column, y, threshold)\n",
        "            if gain > best_gain:\n",
        "                best_gain, best_feature, best_threshold = gain, feature, threshold\n",
        "\n",
        "    return best_feature, best_threshold\n",
        "\n",
        "# Decision Tree Node\n",
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "# Function to build the ID3 tree\n",
        "def build_tree(X, y, depth=0, max_depth=10):\n",
        "    if len(set(y)) == 1:\n",
        "        return Node(value=Counter(y).most_common(1)[0][0])\n",
        "\n",
        "    if depth >= max_depth:\n",
        "        return Node(value=Counter(y).most_common(1)[0][0])\n",
        "\n",
        "    feature, threshold = best_split(X, y)\n",
        "    if feature is None:\n",
        "        return Node(value=Counter(y).most_common(1)[0][0])\n",
        "\n",
        "    left_mask = X[:, feature] <= threshold\n",
        "    right_mask = X[:, feature] > threshold\n",
        "    left_subtree = build_tree(X[left_mask], y[left_mask], depth + 1, max_depth)\n",
        "    right_subtree = build_tree(X[right_mask], y[right_mask], depth + 1, max_depth)\n",
        "\n",
        "    return Node(feature, threshold, left_subtree, right_subtree)\n",
        "\n",
        "# Train the ID3 decision tree\n",
        "tree = build_tree(X_train, y_train)\n",
        "\n",
        "# Function to make predictions\n",
        "def predict(tree, X):\n",
        "    if tree.value is not None:\n",
        "        return tree.value\n",
        "    if X[tree.feature] <= tree.threshold:\n",
        "        return predict(tree.left, X)\n",
        "    else:\n",
        "        return predict(tree.right, X)\n",
        "\n",
        "# Function to print the tree\n",
        "def print_tree(node, depth=0):\n",
        "    if node.value is not None:\n",
        "        print(\"  \" * depth + f\"Leaf: {node.value}\")\n",
        "        return\n",
        "    print(\"  \" * depth + f\"Feature {node.feature} <= {node.threshold}\")\n",
        "    print_tree(node.left, depth + 1)\n",
        "    print_tree(node.right, depth + 1)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = np.array([predict(tree, x) for x in X_test])\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "\n",
        "print(f\"Decision Tree Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"Decision Tree Structure:\")\n",
        "print_tree(tree)"
      ]
    }
  ]
}
